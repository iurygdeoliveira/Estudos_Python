{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Project 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** A classificação é utilizada quando temos resultados discretos, ou seja, os valores finais são finitos. Na regressão, os valores numéricos correspondem a uma escala contínua, infinitos. \n",
    "\n",
    "Neste problema é necessário identificar que temos dois resultados possíveis: reprovado ou aprovado. Assim este é um problema de aprendizagem supervisionada de **classificação**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print (\"Os dados dos estudantes foram lidos com êxito!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "n_students = student_data.shape[0]\n",
    "\n",
    "n_features = student_data.shape[1]-1\n",
    "\n",
    "n_passed = student_data[(student_data.passed == 'yes')].shape[0]\n",
    "\n",
    "n_failed = student_data[(student_data.passed == 'no')].shape[0]\n",
    "\n",
    "grad_rate = (float(n_passed) / float(n_students))*100 \n",
    "\n",
    "print(\"Número total de estudantes: {}\".format(n_students))\n",
    "print(\"Número de atributos: {}\".format(n_features))\n",
    "print(\"Número de estudantes aprovados: {}\".format(n_passed))\n",
    "print(\"Número de estudantes reprovados: {}\".format(n_failed))\n",
    "print(\"Taxa de graduação: {:.2f}%\".format(grad_rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-b1765cd70a4e>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b1765cd70a4e>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    print \"Colunas de atributos:\\n{}\".format(feature_cols)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns)\n",
    "\n",
    "# Extraia a coluna-alvo, 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudando um pouco as informações dos atributos:<br>\n",
    "\n",
    "| Atributo | Tipo | Descrição |\n",
    "| :------ | :-- | :------- | \n",
    "|'school'| binário| Indica a escola do estudante (‘GP’ - Gabriel Pereira, ‘MS’ - Mousinho da Silveira)|\n",
    "|'sex'| binário| ‘F’ - Female or 'M' - Male|\n",
    "|'age'| numérico| Idade do estudante (de 15 a 22 anos)|\n",
    "|'address'| binário| Tipo do endereço da casa do estudante ('U' - urbano ou 'R' - rural)|\n",
    "|'famsize'| binário| Tamanho da família (LE3 - menos ou igual a 3, GT3 - maior que 3)|\n",
    "|'Pstatus'| binário| 'T' - Pais morando juntos ou 'A' - Pais separados)|\n",
    "|'Medu'| numérico| Nível de educação da mãe, (0 - nenhum, 1 - educação primária (4ª série), 2 - 5ª a 9ª série, 3 - educação secundária ou 4 - ensino superior)|\n",
    "|'Fedu'| numérico| Nível de educação do pai, (0 - nenhum, 1 - educação primária (4ª série), 2 - 5ª a 9ª série, 3 - educação secundária ou 4 - ensino superior)|\n",
    "|'Mjob'| nominal| Trabalho da mãe ('teacher' - professora, 'health' relacionado a saúde, civil 'services' (exemplo, administrativo ou polícia), 'at_home' (em casa) or 'other' (outros))|\n",
    "|'Fjob'| nominal| Trabalho do pai ('teacher' - professor, 'health' relacionado a saúde, civil 'services'  (serviços civis, exemplo, administrativo ou polícia), 'at_home' (em casa) or 'other' (outros))|\n",
    "|'reason'| nominal| Razão de escolha da escola(close to 'home' - perto de casa, school 'reputation' - reputação da escola, 'course' preference - preferência do curso, ou 'other' - outros)|\n",
    "|'guardian' | nominal| Guarda do aluno ('mother' - mãe, 'father' - pai ou 'other' - outros)|\n",
    "|'traveltime' | numérico | Tempo de viagem de casa até a escola (1 - <15 min., 2 - 15 a 30 min., 3 - 30 min. a 1 hora, ou 4 - >1 hora)|\n",
    "|'studytime'| numérico| Tempo semanal de estudo (1 - <2 horas, 2 - 2 a 5 horas, 3 - 5 a 10 horas, ou 4 - >10 horas)|\n",
    "|'failures'| numérico| Número de faltas em classes anteriores (n if 1<=n<3, else 4)|\n",
    "|'schoolsup'| binário| Suporte educacional extra (yes/no)|\n",
    "|'famsup'| binário| Suporte educacional da família (yes/no)|\n",
    "|'paid'| binário| Pagamento extra de aulas (matemática ou português) (yes/no)|\n",
    "|'activities'| binário| Atividades extracurriculares (yes/no)|\n",
    "|'nursery'| binário| Frequentou escola maternal (yes/no)|\n",
    "|'higher'| binário| Quer fazer curso superior (yes/no)|\n",
    "|'internet'| binário| Possui acesso a internet em casa (yes/no)|\n",
    "|'romantic'| binário| Possui relacionamento romântico (yes/no)|\n",
    "|'famrel'| numérico| Qualidade do relacionamento familiar (de 1 - muito ruim a 5 - excelente)|\n",
    "|'freetime'| numérico| tempo livre depois da escola (de 1 - muito baixo a 5 - muito alto)|\n",
    "|'goout'| numérico| Sai com os amigos (de 1 - pouco a 5 - muito)|\n",
    "|'Dalc'| numérico| Consumo de álcool em dia de semana (de 1 - muito baixo a 5 - muito alto)|\n",
    "|'Walc'| numérico| Consumo de álcool em fim de semana (de 1 - muito baixo a 5 - muito alto)|\n",
    "|'health'| numérico| Atual estado de saúde (de 1 - muito ruim a 5 - muito bom)|\n",
    "|'absences'| numérico|Ausências escolares (de 0 a 93)|\n",
    "|'passed'| binário| Indica se o aluno passou (yes/no)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (em inglês: _dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "#num_test = X_all.shape[0] - num_train\n",
    "\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=num_train, random_state=42)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Support Vector Classification**<br>\n",
    "\n",
    "<u>Exemplo de utilização</u><br>\n",
    "Melhorando a generalização de Linear Support Vector Machines: um aplicativo para reconhecimento de objetos 3D com fundo desordenado. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.6752&rep=rep1&type=pdf\n",
    "\n",
    "<u>Vantagens</u>\n",
    "- Eficaz em espaços altamente dimensionais, que são modelos de conjuntos de dados com muitos atributos, pondendo ser representado onde cada registro é representado no espaço com sua posição. \n",
    "- Eficaz nos casos em que o número de dimensões é maior do que o número de amostras.\n",
    "- Eficiente em memória, pois utiliza um subconjunto de pontos de treinamento na função de decisão (chamado de vetores de suporte).\n",
    "\n",
    "\n",
    "<u>Desvantagem</u>\n",
    "- Não funcionam muito bem quando o conjunto de dados for muito grande.\n",
    "- O tempo de treinamento é o cúbico no tamanho do conjunto de dados.\n",
    "- Também apresentam desempenho inferior quando há grandes quantidades de ruído nos dados.\n",
    "- Quando não há uma margem de divisão clara, também não funcionam muito bem.\n",
    "\n",
    "<u>Porque escolheria</u>\n",
    "- É um algoritmo rápido e robusto.\n",
    "- É uma das primeiras opções de algoritmos para classificação quando se tem menos de 100K de amostras.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors**<br>\n",
    "\n",
    "<u>Exemplo de utilização</u><br>\n",
    "Aplicação do algoritmo K-nearest neighbors sobre problema de diagnóstico de câncer de mama. <br>\n",
    "Neste paper o autor fala que o resultado de classificação geral 1,17% melhor que o melhor resultado conhecido por esse problema.<br>\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2243774/\n",
    "\n",
    "\n",
    "<u>Vantagens</u>\n",
    " - Robusto mesmo em dados com ruídos.\n",
    " - Eficaz mesmo se os dados de treinamento forem grandes.\n",
    " - Sem custo computacional no treinamento.\n",
    " \n",
    "<u>Desvantagem</u>\n",
    "- Desempenho inferior com poucos dados de treinamento.\n",
    "- O custo de computação e memória é bastante elevado porque precisamos calcular a distância de cada instância de consulta para todas as amostras de treinamento.\n",
    "- O algoritmo apenas computa a distância entre os dados vizinhos, não \"aprende\" com os dados de treinamento, o que acaba não generalizando bem.\n",
    "\n",
    "<u>Porque escolheria</u>\n",
    "- Como o tempo de treinamento é baixo, é um bom candidato, pois o custo de computação não é alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**\n",
    "\n",
    "<u>Exemplo de utilização</u><br>\n",
    "Classificação de precursores reais e pseudo microRNA usando modelo de previsão Random Forest com características combinadas. Neste paper, os resultados sugerem que o método prevê uma especificidade de 98,21% e uma sensibilidade de 95,09%.<br>\n",
    "Fonte: https://academic.oup.com/nar/article/35/suppl_2/W339/2923422\n",
    "\n",
    "<u>Vantagens</u><br>\n",
    "- Por usar várias árvores de decisão, possui um desempenho melhor do que apenas uma árvore de decisão.\n",
    "- Ele pode lidar com milhares de variáveis de entrada sem exclusão variável.\n",
    "- Mostra a estimativa de quais variáveis são mais importantes na classificação.\n",
    "\n",
    "<u>Desvantagens</u><br>\n",
    "- Overfitting em dados com muito ruído.\n",
    "- Quando há várias features, porém somente alguns deles são úteis, o desempenho acaba sendo pior.\n",
    "- Difente de apenas uma árvore, Random Forest não é tão fácil interpretar visualmente. \n",
    "\n",
    "**Porque utilizaria** <br>\n",
    "- São vários atributos de entrada correlacionados, como ele trabalha bem com várias entradas, acredito que é uma boa escolha.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    print \"Accuracy Score {}\".format(accuracy_score (target.values, y_pred))\n",
    "    print \"Recall Score {}\".format(recall_score (target.values, y_pred, average=None))\n",
    "    print \"Precision Score {}\".format(precision_score (target.values, y_pred, pos_label='yes'))\n",
    "\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando um LinearSVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0112 segundos\n",
      "As previsões foram feitas em 0.0021 segundos.\n",
      "Accuracy Score 0.83\n",
      "Recall Score [ 0.58333333  0.96875   ]\n",
      "Precision Score 0.805194805195\n",
      "Pontuação F1 para o conjunto de treino: 0.8794.\n",
      "As previsões foram feitas em 0.0002 segundos.\n",
      "Accuracy Score 0.652631578947\n",
      "Recall Score [ 0.31428571  0.85      ]\n",
      "Precision Score 0.68\n",
      "Pontuação F1 para o conjunto de teste: 0.7556.\n",
      "\n",
      "Treinando um LinearSVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0185 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Accuracy Score 0.77\n",
      "Recall Score [ 0.72580645  0.78985507]\n",
      "Precision Score 0.865079365079\n",
      "Pontuação F1 para o conjunto de treino: 0.8258.\n",
      "As previsões foram feitas em 0.0002 segundos.\n",
      "Accuracy Score 0.715789473684\n",
      "Recall Score [ 0.48571429  0.85      ]\n",
      "Precision Score 0.739130434783\n",
      "Pontuação F1 para o conjunto de teste: 0.7907.\n",
      "\n",
      "Treinando um LinearSVC com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0282 segundos\n",
      "As previsões foram feitas em 0.0003 segundos.\n",
      "Accuracy Score 0.766666666667\n",
      "Recall Score [ 0.36842105  0.95121951]\n",
      "Precision Score 0.764705882353\n",
      "Pontuação F1 para o conjunto de treino: 0.8478.\n",
      "As previsões foram feitas em 0.0002 segundos.\n",
      "Accuracy Score 0.694736842105\n",
      "Recall Score [ 0.31428571  0.91666667]\n",
      "Precision Score 0.696202531646\n",
      "Pontuação F1 para o conjunto de teste: 0.7914.\n",
      "\n",
      "Treinando um KNeighborsClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0005 segundos\n",
      "As previsões foram feitas em 0.0017 segundos.\n",
      "Accuracy Score 0.74\n",
      "Recall Score [ 0.55555556  0.84375   ]\n",
      "Precision Score 0.771428571429\n",
      "Pontuação F1 para o conjunto de treino: 0.8060.\n",
      "As previsões foram feitas em 0.0017 segundos.\n",
      "Accuracy Score 0.6\n",
      "Recall Score [ 0.2         0.83333333]\n",
      "Precision Score 0.641025641026\n",
      "Pontuação F1 para o conjunto de teste: 0.7246.\n",
      "\n",
      "Treinando um KNeighborsClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0006 segundos\n",
      "As previsões foram feitas em 0.0031 segundos.\n",
      "Accuracy Score 0.82\n",
      "Recall Score [ 0.51612903  0.95652174]\n",
      "Precision Score 0.814814814815\n",
      "Pontuação F1 para o conjunto de treino: 0.8800.\n",
      "As previsões foram feitas em 0.0021 segundos.\n",
      "Accuracy Score 0.652631578947\n",
      "Recall Score [ 0.2         0.91666667]\n",
      "Precision Score 0.66265060241\n",
      "Pontuação F1 para o conjunto de teste: 0.7692.\n",
      "\n",
      "Treinando um KNeighborsClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0008 segundos\n",
      "As previsões foram feitas em 0.0059 segundos.\n",
      "Accuracy Score 0.823333333333\n",
      "Recall Score [ 0.53684211  0.95609756]\n",
      "Precision Score 0.816666666667\n",
      "Pontuação F1 para o conjunto de treino: 0.8809.\n",
      "As previsões foram feitas em 0.0026 segundos.\n",
      "Accuracy Score 0.673684210526\n",
      "Recall Score [ 0.25714286  0.91666667]\n",
      "Precision Score 0.679012345679\n",
      "Pontuação F1 para o conjunto de teste: 0.7801.\n",
      "\n",
      "Treinando um RandomForestClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0226 segundos\n",
      "As previsões foram feitas em 0.0052 segundos.\n",
      "Accuracy Score 0.98\n",
      "Recall Score [ 0.97222222  0.984375  ]\n",
      "Precision Score 0.984375\n",
      "Pontuação F1 para o conjunto de treino: 0.9844.\n",
      "As previsões foram feitas em 0.0053 segundos.\n",
      "Accuracy Score 0.589473684211\n",
      "Recall Score [ 0.2         0.81666667]\n",
      "Precision Score 0.636363636364\n",
      "Pontuação F1 para o conjunto de teste: 0.7153.\n",
      "\n",
      "Treinando um RandomForestClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0280 segundos\n",
      "As previsões foram feitas em 0.0053 segundos.\n",
      "Accuracy Score 0.995\n",
      "Recall Score [ 0.98387097  1.        ]\n",
      "Precision Score 0.992805755396\n",
      "Pontuação F1 para o conjunto de treino: 0.9964.\n",
      "As previsões foram feitas em 0.0057 segundos.\n",
      "Accuracy Score 0.684210526316\n",
      "Recall Score [ 0.28571429  0.91666667]\n",
      "Precision Score 0.6875\n",
      "Pontuação F1 para o conjunto de teste: 0.7857.\n",
      "\n",
      "Treinando um RandomForestClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0303 segundos\n",
      "As previsões foram feitas em 0.0092 segundos.\n",
      "Accuracy Score 0.993333333333\n",
      "Recall Score [ 0.98947368  0.99512195]\n",
      "Precision Score 0.99512195122\n",
      "Pontuação F1 para o conjunto de treino: 0.9951.\n",
      "As previsões foram feitas em 0.0056 segundos.\n",
      "Accuracy Score 0.736842105263\n",
      "Recall Score [ 0.48571429  0.88333333]\n",
      "Precision Score 0.746478873239\n",
      "Pontuação F1 para o conjunto de teste: 0.8092.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = LinearSVC(random_state=42)\n",
    "clf_B = KNeighborsClassifier()\n",
    "clf_C = RandomForestClassifier(random_state=42)\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    for n_train in [100, 200, 300]:\n",
    "        train_predict(clf, \n",
    "                      X_train[:n_train], y_train[:n_train], \n",
    "                      X_test, y_test)\n",
    "        print ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Tabulados\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 2 - LinearSVC**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                | 0.0090               |    0.0010                  | 0.8905                  | 0.7463                     |\n",
    "| 200                                |       0.0170        |   0.0000                    |  0.8523                  | 0.7737               |\n",
    "| 300                                |  0.0280            |      0.0000                  |  0.5993                   |       0.6471      |\n",
    "\n",
    "** Classificador 3 - KNeighborsClassifier**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                | 0.0000               |   0.0020                    |    0.8060                 |  0.7246              |\n",
    "| 200                                |  0.0010              |   0.0030                    |   0.8800                |  0.7692            |\n",
    "| 300                                | 0.0010               |  0.0040                     |  0.8809                   | 0.7801             |\n",
    "\n",
    "** Classificador 3 - RandomForestClassifier**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |  0.0318              |  0.0053                     |   0.9844                     | 0.7153                     |\n",
    "| 200                                |       0.0264        |      0.0056              |    0.9964                   | 0.7857                     |\n",
    "| 300                                |    0.0269           |     0.0054                |   0.9951                   |        0.8092       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "O modelo que teve o pior desempenho na pontuação F1 dos testes foi LinearSVC. Isso se deve ao fato que provavelmente estes dados não são muito bem divididos linearmente. O tempo de treinamento também aumenta significativamente ao aumentar o conjunto de dados, enquanto que ele é muito rápido em estimar. Apesar do bom desempenho na velocidade de estimar os dados de testes, este não se mostrou um bom modelo, pois a pontuação F1 nos testes foi bem inferior comparando com os outros algoritmos, principalmente no conjunto de 300 pontos.<br>\n",
    "\n",
    "Levando em consideração o tempo de treinamento, como esperado, o modelo mais rápido é o KNeighborsClassifier, levando 0.0010 segundos no máximo. O tempo de estimativa percebeu-se que aumentou proporcionalmente ao tamanho do conjunto de pontos de testes, caso tivesse muito mais dados, o custo computacional para previsão seria muito alto. A pontuação F1 deste modelo ficou razoavel. <br>\n",
    "\n",
    "RandomForestClassifier teve o maior tempo de treinamento no conjunto de 100 e 200 pontos, porém em 300 pontos percebe-se que ele tem o desempenho melhor que o LinearSVC. O tempo de testes também foi maior entre os modelos, entretanto a variação de tempo entre o conjunto de dados (100, 200 e 300) não é muito grande. Foi o classificador que teve o **melhor desempenho na pontuação F1**, por isso eu escolho **RandomForestClassifier como melhor modelo**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As árvores de decisão são fáceis de entender, pois criam regras de decisões.\n",
    "Exemplo, se (modelo do carro é X) e (cidade de emplacamento y) e (tem z anos de fabricação) e (teve k donos) então (seu preço de venda é 30000). <br>\n",
    "\n",
    "Tem este nome pois sua estrutura se assemelha a uma árvore, com uma raíz e folhas. <br>\n",
    "\n",
    "Random Forest (florestas aleatórias) estende as árvores de decisão, incluindo várias árvores, com amostras aleatórias dos dados, combinando de diferentes formas os atributos. <br>\n",
    "Ou seja, em vez de usar apenas uma árvore, com uma visão, esta abordagem utiliza uma coleção de árvores, cada uma montada utilizando dados aleatórios, com diferentes visões e resultados. <br>\n",
    "\n",
    "Ao final este modelo combina o resultado de classificação de cada árvore de decisão, garantindo um desempenho melhor do que se fosse utilizar apenas uma árvore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=30, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=900, n_jobs=1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False)\n",
      "As previsões foram feitas em 0.5329 segundos.\n",
      "Accuracy Score 1.0\n",
      "Recall Score [ 1.  1.]\n",
      "Precision Score 1.0\n",
      "O modelo calibrado tem F1 de 1.0000 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.4363 segundos.\n",
      "Accuracy Score 0.726315789474\n",
      "Recall Score [ 0.34285714  0.95      ]\n",
      "Precision Score 0.7125\n",
      "O modelo calibrado tem F1 de 0.8143 no conjunto de teste.\n",
      "Ranking de Atributos:\n",
      "1. atributo 47-absences (0.117940879872)\n",
      "2. atributo 32-failures (0.0962996021213)\n",
      "3. atributo 43-goout (0.0588489366795)\n",
      "4. atributo 4-age (0.0521122155093)\n",
      "5. atributo 42-freetime (0.0391359207015)\n",
      "6. atributo 46-health (0.038318818178)\n",
      "7. atributo 31-studytime (0.0365277421728)\n",
      "8. atributo 11-Medu (0.0344616786914)\n",
      "9. atributo 12-Fedu (0.0331250031165)\n",
      "10. atributo 41-famrel (0.0325845692597)\n",
      "11. atributo 45-Walc (0.0286766401126)\n",
      "12. atributo 33-schoolsup (0.0235807236453)\n",
      "13. atributo 44-Dalc (0.0215684329096)\n",
      "14. atributo 38-higher (0.0205383172724)\n",
      "15. atributo 30-traveltime (0.0190936694658)\n",
      "16. atributo 35-paid (0.0180183911993)\n",
      "17. atributo 34-famsup (0.017467345947)\n",
      "18. atributo 29-guardian_other (0.0160410763849)\n",
      "19. atributo 37-nursery (0.0145295379336)\n",
      "20. atributo 23-reason_course (0.0144686986777)\n",
      "21. atributo 36-activities (0.0140728979805)\n",
      "22. atributo 13-Mjob_at_home (0.0138156834145)\n",
      "23. atributo 39-internet (0.0135163963229)\n",
      "24. atributo 15-Mjob_other (0.0124635777841)\n",
      "25. atributo 18-Fjob_at_home (0.0118799815393)\n",
      "26. atributo 40-romantic (0.0118544093448)\n",
      "27. atributo 3-sex_M (0.0114444240538)\n",
      "28. atributo 16-Mjob_services (0.0114187839842)\n",
      "29. atributo 26-reason_reputation (0.0111364630101)\n",
      "30. atributo 27-guardian_father (0.010785555836)\n",
      "31. atributo 17-Mjob_teacher (0.0107433037517)\n",
      "32. atributo 20-Fjob_other (0.0103754542859)\n",
      "33. atributo 2-sex_F (0.0101396157004)\n",
      "34. atributo 7-famsize_GT3 (0.00999779769965)\n",
      "35. atributo 28-guardian_mother (0.00995833585879)\n",
      "36. atributo 8-famsize_LE3 (0.00989127327562)\n",
      "37. atributo 24-reason_home (0.00910353388273)\n",
      "38. atributo 21-Fjob_services (0.00904372467544)\n",
      "39. atributo 25-reason_other (0.00856126697852)\n",
      "40. atributo 19-Fjob_health (0.00718642670536)\n",
      "41. atributo 5-address_R (0.0071754312602)\n",
      "42. atributo 6-address_U (0.00715841451836)\n",
      "43. atributo 10-Pstatus_T (0.00660501371856)\n",
      "44. atributo 14-Mjob_health (0.00629225515936)\n",
      "45. atributo 9-Pstatus_A (0.00621906983546)\n",
      "46. atributo 1-school_MS (0.0055210058098)\n",
      "47. atributo 22-Fjob_teacher (0.00519981057433)\n",
      "48. atributo 0-school_GP (0.00510189318929)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters =  {'n_estimators':[10,500,600,700,800,900,1000,1500],\n",
    "               'max_features':[15,30,40,n_features]}\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring=f1_scorer, verbose=1)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "print clf\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Ranking de Atributos:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"{}. atributo {}-{} ({})\".format(f + 1, indices[f], X_all.columns[indices[f]], importances[indices[f]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pontuação F1 para o modelo calibrado ficou em 0.8143, já o modelo não calibrado em 300 pontos ficou com pontuação F1 0.8092. Foi possível perceber uma melhora no modelo calibrado em 0.63%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
